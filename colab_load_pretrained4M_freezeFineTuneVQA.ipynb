{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaixinLiuNeuro/ALBEF/blob/main/colab_load_pretrained4M_freezeFineTuneVQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24nSaNVhFajG"
      },
      "source": [
        "# Load pretrained 4M model, freeze encoder's parameters fine-tune with only VQA dataset, run evaluation test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jpeIswepIcEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c969aa-4ffb-4ae2-cdce-27561ba1f6b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-C2cjy7sLsaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d3e730-583b-4938-8fda-880880488980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['output', 'vqa_end2end', 'vqa_onlyPretrainModel', 'vqa_nopretrain_noTune']\n"
          ]
        }
      ],
      "source": [
        "# setup drive folder\n",
        "import os\n",
        "\n",
        "# TODO: Fill in the Google Drive path where you want to save result\n",
        "GOOGLE_DRIVE_PATH_POST_MYDRIVE = os.path.join('DL_Project', 'ALBEF')\n",
        "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
        "os.makedirs(GOOGLE_DRIVE_PATH, exist_ok=True)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3gnMy6WHMjZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb009434-8f93-4d9f-df18-57d9afe7e835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in google colab. Our path is `/content/drive/MyDrive/DL_Project/ALBEF`\n"
          ]
        }
      ],
      "source": [
        "# if running locally set GOOGLE PATH\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
        "else:\n",
        "  GOOGLE_DRIVE_PATH = '.'\n",
        "  print('Running locally.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7vaWO3M8Mmxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5433be63-36f7-405c-86f0-e02053908315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive Path: /content/drive/MyDrive/DL_Project/ALBEF\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)\n",
        "print(f'Google Drive Path: {GOOGLE_DRIVE_PATH}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cj6rXs28G5ck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fb4ea3d-488b-4c6b-84ca-bdd33ee63359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/tmp/ALBEF'...\n",
            "remote: Enumerating objects: 402, done.\u001b[K\n",
            "remote: Counting objects: 100% (240/240), done.\u001b[K\n",
            "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
            "remote: Total 402 (delta 138), reused 124 (delta 122), pack-reused 162 (from 2)\u001b[K\n",
            "Receiving objects: 100% (402/402), 71.62 MiB | 68.35 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repo to a content\n",
        "!git clone -b main https://github.com/HaixinLiuNeuro/ALBEF.git /tmp/ALBEF\n",
        "!cp -r /tmp/ALBEF/* .\n",
        "!rm -rf /tmp/ALBEF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "N_7q2p11MyGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb51790c-cc58-47cc-9ff3-ec59c05a2827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.25.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1)\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2025.1.31)\n",
            "Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.25.1\n",
            "Collecting ruamel.yaml==0.17.*\n",
            "  Downloading ruamel.yaml-0.17.40-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml==0.17.*)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading ruamel.yaml-0.17.40-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml\n",
            "Successfully installed ruamel.yaml-0.17.40 ruamel.yaml.clib-0.2.12\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# install dependency\n",
        "!pip install transformers==4.25.1\n",
        "!pip install ruamel.yaml==0.17.*\n",
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nQxFlSxfFajH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cf362f-a346-4d37-b9d6-19dbaff58782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# import\n",
        "import argparse\n",
        "import os\n",
        "import ruamel.yaml as yaml\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "\n",
        "# use vqa model\n",
        "from models.model_vqa_freeze import ALBEF\n",
        "\n",
        "from models.vit import interpolate_pos_embed\n",
        "from models.tokenization_bert import BertTokenizer\n",
        "\n",
        "import utils\n",
        "from dataset.utils import save_result\n",
        "from dataset import create_dataset, create_sampler, create_loader, vqa_collate_fn\n",
        "\n",
        "from scheduler import create_scheduler\n",
        "from optim import create_optimizer\n",
        "\n",
        "# print and plotting\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JiebcG8heA07"
      },
      "outputs": [],
      "source": [
        "# %reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kPxGkhRy4FLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf27184e-29d4-4eb5-e92a-9373b7998332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "Downloading data.tar.gz...\n",
            "data.tar.gz         100%[===================>] 137.87M   150MB/s    in 0.9s    \n",
            "Extracting data.tar.gz...\n",
            "^C\n",
            "Removing data.tar.gz...\n",
            "Finished processing data.tar.gz\n",
            "Downloading train2014.zip...\n",
            "train2014.zip         6%[>                   ] 826.35M  53.1MB/s    eta 3m 33s ^C\n",
            "Extracting train2014.zip...\n",
            "[train2014.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of train2014.zip or\n",
            "        train2014.zip.zip, and cannot find train2014.zip.ZIP, period.\n",
            "Removing train2014.zip...\n",
            "Finished processing train2014.zip\n",
            "Downloading val2014.zip...\n",
            "val2014.zip           7%[>                   ] 480.01M  58.4MB/s    eta 99s    ^C\n",
            "Extracting val2014.zip...\n",
            "[val2014.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of val2014.zip or\n",
            "        val2014.zip.zip, and cannot find val2014.zip.ZIP, period.\n",
            "Removing val2014.zip...\n",
            "Finished processing val2014.zip\n",
            "Downloading test2015.zip...\n",
            "test2015.zip          2%[                    ] 278.33M  50.8MB/s    eta 4m 9s  ^C\n",
            "Extracting test2015.zip...\n",
            "[test2015.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of test2015.zip or\n",
            "        test2015.zip.zip, and cannot find test2015.zip.ZIP, period.\n",
            "Removing test2015.zip...\n",
            "Finished processing test2015.zip\n",
            "All downloads and extractions completed!\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# prep data\n",
        "# download from website\n",
        "\n",
        "# make folder /content/data\n",
        "DATA_PATH = os.path.join('/content', 'data')\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "\n",
        "%cd /content/data\n",
        "\n",
        "# download data from links:\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/json_pretrain.zip\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/data.tar.gz\n",
        "# http://images.cocodataset.org/zips/train2014.zip\n",
        "# http://images.cocodataset.org/zips/val2014.zip\n",
        "# http://images.cocodataset.org/zips/test2015.zip\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the download links\n",
        "links = [\n",
        "    # \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/json_pretrain.zip\", # pretrain json\n",
        "    \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/data.tar.gz\", # for downstream task json\n",
        "    \"http://images.cocodataset.org/zips/train2014.zip\", # comment out if only run evaluation\n",
        "    \"http://images.cocodataset.org/zips/val2014.zip\",   # comment out if only run evaluation\n",
        "    \"http://images.cocodataset.org/zips/test2015.zip\"\n",
        "]\n",
        "\n",
        "# Download and extract each file\n",
        "for link in links:\n",
        "    filename = link.split('/')[-1]\n",
        "    print(f\"Downloading {filename}...\")\n",
        "\n",
        "    # Download file\n",
        "    !wget -q --show-progress {link}\n",
        "\n",
        "    print(f\"Extracting {filename}...\")\n",
        "\n",
        "    # Extract based on file extension\n",
        "    if filename.endswith('.zip'):\n",
        "      if '//images.cocodataset.org/zips/' in link:\n",
        "        !unzip -q {filename}\n",
        "      else:\n",
        "        !unzip -q -j {filename}  # -j option flattens the directory structure for json_pretrain.zip\n",
        "    elif filename.endswith('.tar.gz'):\n",
        "        !tar -xzf {filename} --strip-components=1  # Remove the top-level directory\n",
        "\n",
        "    # Delete the zip/tar file after extraction\n",
        "    print(f\"Removing {filename}...\")\n",
        "    !rm {filename}\n",
        "\n",
        "    print(f\"Finished processing {filename}\")\n",
        "\n",
        "print(\"All downloads and extractions completed!\")\n",
        "\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Sc9XbDXyL4WJ"
      },
      "outputs": [],
      "source": [
        "# !rm -rf /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y9cbgfXjUT_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd6a271a-4064-43a8-b52d-f7513b6fe9af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "coco_test.json\t nlvr_train.json     ve_dev.json   vqa_test_dev.json\n",
            "coco_train.json  refcoco+\t     ve_test.json  vqa_test.json\n",
            "nlvr_test.json\t refcoco+_test.json  vg_qa.json    vqa_train.json\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# check files\n",
        "%cd /content/data\n",
        "!ls\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWKM1ISxSrPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1511d5bf-61e6-4c4a-d35c-e8c31db3cd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading ALBEF_4M.pth...\n",
            "ALBEF_4M.pth         66%[============>       ]   2.17G   184MB/s    eta 6s     "
          ]
        }
      ],
      "source": [
        "#\n",
        "FETCH_PRETRAINED_MODEL = True\n",
        "%cd /content\n",
        "\n",
        "# download data from links:\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/ALBEF_4M.pth\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/vqa.pth\n",
        "# model check point from training\n",
        "# https://drive.google.com/file/d/1yEsyeB0FkIgWlT2Way_KFLPNLCQy6KoU/view?usp=sharing\n",
        "\n",
        "if FETCH_PRETRAINED_MODEL:\n",
        "\n",
        "  # Define the download links\n",
        "  links = [\n",
        "      \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/ALBEF_4M.pth\",\n",
        "      # \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/vqa.pth\"\n",
        "  ]\n",
        "\n",
        "  # Download and extract each file\n",
        "  for link in links:\n",
        "      filename = link.split('/')[-1]\n",
        "      print(f\"Downloading {filename}...\")\n",
        "\n",
        "      # Download file\n",
        "      !wget -q --show-progress {link}\n",
        "\n",
        "\n",
        "      print(f\"Finished processing {filename}\")\n",
        "\n",
        "  print(\"All model downloads completed!\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm5adbe9FajI"
      },
      "source": [
        "## Setup for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SSGJE2MFajI"
      },
      "outputs": [],
      "source": [
        "# config\n",
        "%cd /content\n",
        "args = argparse.Namespace()\n",
        "args.config = './configs/VQA.yaml'\n",
        "args.checkpoint = './ALBEF_4M.pth'\n",
        "args.output_dir = 'output/vqa_PretrainModel_freezeTune'\n",
        "args.evaluate = True # to train use False\n",
        "args.text_encoder = 'bert-base-uncased'\n",
        "args.text_decoder = 'bert-base-uncased'\n",
        "args.device = 'cuda'\n",
        "args.seed = 42\n",
        "args.distributed = False\n",
        "\n",
        "config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)\n",
        "pprint(config)\n",
        "\n",
        "# make result folder and save config\n",
        "args.result_dir = os.path.join(args.output_dir, 'result')\n",
        "\n",
        "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(args.result_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyGrj0NZFajI"
      },
      "outputs": [],
      "source": [
        "# training functions\n",
        "def train(model, data_loader, optimizer, tokenizer, epoch, warmup_steps, device, scheduler, config):\n",
        "    # train\n",
        "    model.train()\n",
        "\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "    metric_logger.add_meter('loss', utils.SmoothedValue(window_size=1, fmt='{value:.4f}'))\n",
        "\n",
        "    header = 'Train Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    step_size = 100\n",
        "    warmup_iterations = warmup_steps*step_size\n",
        "\n",
        "    for i,(image, question, answer, weights, n) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        image, weights = image.to(device,non_blocking=True), weights.to(device,non_blocking=True)\n",
        "        question_input = tokenizer(question, padding='longest', truncation=True, max_length=25, return_tensors=\"pt\").to(device)\n",
        "        answer_input = tokenizer(answer, padding='longest', return_tensors=\"pt\").to(device)\n",
        "\n",
        "        if epoch>0 or not config['warm_up']:\n",
        "            alpha = config['alpha']\n",
        "        else:\n",
        "            alpha = config['alpha']*min(1,i/len(data_loader))\n",
        "\n",
        "        loss = model(image, question_input, answer_input, train=True, alpha=alpha, k=n, weights=weights)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        metric_logger.update(loss=loss.item())\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "        if epoch==0 and i%step_size==0 and i<=warmup_iterations:\n",
        "            scheduler.step(i//step_size)\n",
        "\n",
        "    # gather the stats from all processes\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger.global_avg())\n",
        "    return {k: \"{:.3f}\".format(meter.global_avg) for k, meter in metric_logger.meters.items()}\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluation(model, data_loader, tokenizer, device, config) :\n",
        "    # test\n",
        "    model.eval()\n",
        "\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = 'Generate VQA test result:'\n",
        "    print_freq = 50\n",
        "\n",
        "    result = []\n",
        "\n",
        "    answer_list = [answer+config['eos'] for answer in data_loader.dataset.answer_list]\n",
        "    answer_input = tokenizer(answer_list, padding='longest', return_tensors='pt').to(device)\n",
        "\n",
        "    for n, (image, question, question_id) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        image = image.to(device,non_blocking=True)\n",
        "        question_input = tokenizer(question, padding='longest', return_tensors=\"pt\").to(device)\n",
        "\n",
        "        topk_ids, topk_probs = model(image, question_input, answer_input, train=False, k=config['k_test'])\n",
        "\n",
        "        for ques_id, topk_id, topk_prob in zip(question_id, topk_ids, topk_probs):\n",
        "            ques_id = int(ques_id.item())\n",
        "            _, pred = topk_prob.max(dim=0)\n",
        "            result.append({\"question_id\":ques_id, \"answer\":data_loader.dataset.answer_list[topk_id[pred]]})\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_fo-oPwFajI"
      },
      "outputs": [],
      "source": [
        "# setup for training/evaluation (from main)\n",
        "utils.init_distributed_mode(args)\n",
        "\n",
        "device = torch.device(args.device)\n",
        "print(f'device: {device}')\n",
        "\n",
        "# fix the seed for reproducibility\n",
        "seed = args.seed + utils.get_rank()\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "start_epoch = 0\n",
        "max_epoch = config['schedular']['epochs']\n",
        "warmup_steps = config['schedular']['warmup_epochs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmtKe-XVFajI"
      },
      "outputs": [],
      "source": [
        "# make dataset and dataloader\n",
        "print(\"Creating vqa datasets\")\n",
        "datasets = create_dataset('vqa', config)\n",
        "\n",
        "if args.distributed:\n",
        "    num_tasks = utils.get_world_size()\n",
        "    global_rank = utils.get_rank()\n",
        "    samplers = create_sampler(datasets, [True, False], num_tasks, global_rank)\n",
        "else:\n",
        "    samplers = [None, None]\n",
        "\n",
        "train_loader, test_loader = create_loader(datasets,samplers,\n",
        "                                          batch_size=[config['batch_size_train'],config['batch_size_test']],\n",
        "                                          num_workers=[4,4],is_trains=[True, False],\n",
        "                                          collate_fns=[vqa_collate_fn,None])\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(args.text_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zYcjMhhFajI"
      },
      "outputs": [],
      "source": [
        "#### Model ####\n",
        "print(\"Creating model\")\n",
        "model = ALBEF(config=config, text_encoder=args.text_encoder, text_decoder=args.text_decoder, tokenizer=tokenizer)\n",
        "model = model.to(device)\n",
        "\n",
        "arg_opt = utils.AttrDict(config['optimizer'])\n",
        "optimizer = create_optimizer(arg_opt, model)\n",
        "arg_sche = utils.AttrDict(config['schedular'])\n",
        "lr_scheduler, _ = create_scheduler(arg_sche, optimizer)\n",
        "\n",
        "# check model\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B64EarwbFajJ"
      },
      "outputs": [],
      "source": [
        "# load check point to continue training\n",
        "if args.checkpoint:\n",
        "    checkpoint = torch.load(args.checkpoint, map_location='cpu')\n",
        "    if args.evaluate:\n",
        "        state_dict = checkpoint\n",
        "    else:\n",
        "        state_dict = checkpoint['model']\n",
        "\n",
        "    # with checkpoint of vqa model\n",
        "    # reshape positional embedding to accomodate for image resolution change\n",
        "    # pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder.pos_embed'],model.visual_encoder)\n",
        "    # state_dict['visual_encoder.pos_embed'] = pos_embed_reshaped\n",
        "\n",
        "    # Check if the key exists before accessing it\n",
        "    if 'visual_encoder.pos_embed' in state_dict:\n",
        "        # reshape positional embedding to accomodate for image resolution change\n",
        "        pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder.pos_embed'],model.visual_encoder)\n",
        "        state_dict['visual_encoder.pos_embed'] = pos_embed_reshaped\n",
        "    else:\n",
        "        print(\"Warning: 'visual_encoder.pos_embed' not found in checkpoint. Skipping positional embedding interpolation.\")\n",
        "\n",
        "\n",
        "    if not args.evaluate:\n",
        "        if config['distill']:\n",
        "            m_pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder_m.pos_embed'],model.visual_encoder_m)\n",
        "            state_dict['visual_encoder_m.pos_embed'] = m_pos_embed_reshaped\n",
        "\n",
        "        for key in list(state_dict.keys()):\n",
        "            if 'bert' in key:\n",
        "                encoder_key = key.replace('bert.','')\n",
        "                state_dict[encoder_key] = state_dict[key]\n",
        "            # intialize text decoder as multimodal encoder (last 6 layers of model.text_encoder)\n",
        "            if 'text_encoder' in key:\n",
        "                if 'layer' in key:\n",
        "                    # print(key)\n",
        "                    encoder_keys = key.split('.')\n",
        "                    print(encoder_keys)\n",
        "                    # print(encoder_keys[4])\n",
        "                    tmp_fix_idx = 4 # for the downsized model, idx 5 is the layer number\n",
        "                    layer_num = int(encoder_keys[tmp_fix_idx]) # 4\n",
        "                    if layer_num<6:\n",
        "                        del state_dict[key]\n",
        "                        continue\n",
        "                    else:\n",
        "                        decoder_layer_num = (layer_num-6)\n",
        "                        encoder_keys[4] = str(decoder_layer_num)\n",
        "                        encoder_key = '.'.join(encoder_keys)\n",
        "                else:\n",
        "                    encoder_key = key\n",
        "                decoder_key = encoder_key.replace('text_encoder','text_decoder')\n",
        "                state_dict[decoder_key] = state_dict[key]\n",
        "\n",
        "                del state_dict[key]\n",
        "\n",
        "    msg = model.load_state_dict(state_dict,strict=False)\n",
        "    print('load checkpoint from %s'%args.checkpoint)\n",
        "    print(msg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJmSxRhtFajJ"
      },
      "outputs": [],
      "source": [
        "# handle distributed training\n",
        "model_without_ddp = model\n",
        "if args.distributed:\n",
        "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
        "    model_without_ddp = model.module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VyQyvZE1FajJ"
      },
      "outputs": [],
      "source": [
        "# run evaluation without training single GPU\n",
        "print(\"Start eval\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(start_epoch, max_epoch):\n",
        "    if epoch>0:\n",
        "        lr_scheduler.step(epoch+warmup_steps)\n",
        "\n",
        "    if not args.evaluate:\n",
        "        if args.distributed:\n",
        "            train_loader.sampler.set_epoch(epoch)\n",
        "\n",
        "        train_stats = train(model, train_loader, optimizer, tokenizer, epoch, warmup_steps, device, lr_scheduler, config)\n",
        "\n",
        "    if args.evaluate:\n",
        "        break\n",
        "\n",
        "    if utils.is_main_process():\n",
        "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
        "                      'epoch': epoch,\n",
        "                    }\n",
        "        with open(os.path.join(args.output_dir, \"log.txt\"),\"a\") as f:\n",
        "            f.write(json.dumps(log_stats) + \"\\n\")\n",
        "\n",
        "        save_obj = {\n",
        "            'model': model_without_ddp.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'lr_scheduler': lr_scheduler.state_dict(),\n",
        "            'config': config,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        torch.save(save_obj, os.path.join(args.output_dir, 'checkpoint_%02d.pth'%epoch))\n",
        "\n",
        "        # save result to google drive\n",
        "        !cp -r {args.output_dir} {GOOGLE_DRIVE_PATH}\n",
        "\n",
        "    if args.distributed:\n",
        "        dist.barrier()\n",
        "    else:\n",
        "        pass  # Skip barrier for non-distributed training\n",
        "\n",
        "# evaluation\n",
        "vqa_result = evaluation(model, test_loader, tokenizer, device, config)\n",
        "result_file = save_result(vqa_result, args.result_dir, 'vqa_result_epoch%d'%epoch)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print('Time time {}'.format(total_time_str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T52hIhCtaoJ0"
      },
      "outputs": [],
      "source": [
        "print(f'google drive: {GOOGLE_DRIVE_PATH} from colab drive: {args.output_dir}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmVYMgYzgka2"
      },
      "outputs": [],
      "source": [
        "# save result to google drive\n",
        "!cp -r {args.output_dir} {GOOGLE_DRIVE_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o33GkkgsBGD"
      },
      "outputs": [],
      "source": [
        "# terminate colab runtime\n",
        "from google.colab import runtime\n",
        "runtime.unassign()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
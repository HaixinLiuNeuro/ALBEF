{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaixinLiuNeuro/ALBEF/blob/main/colab_load_pretrained4M_vqaFineTune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24nSaNVhFajG"
      },
      "source": [
        "# Load pretrained model, fine-tune with only VQA dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "jpeIswepIcEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f842c0-1121-4b06-88b8-81bd63e3ed48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup drive folder\n",
        "import os\n",
        "\n",
        "# TODO: Fill in the Google Drive path where you want to save result\n",
        "GOOGLE_DRIVE_PATH_POST_MYDRIVE = os.path.join('DL_Project', 'ALBEF')\n",
        "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
        "os.makedirs(GOOGLE_DRIVE_PATH, exist_ok=True)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))"
      ],
      "metadata": {
        "id": "-C2cjy7sLsaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e8e67b-fba0-4f4e-cd75-5a1a8e17f9e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if running locally set GOOGLE PATH\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
        "else:\n",
        "  GOOGLE_DRIVE_PATH = '.'\n",
        "  print('Running locally.')"
      ],
      "metadata": {
        "id": "3gnMy6WHMjZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23ddbfc-eeb3-4b51-b3a5-3db85af2b9f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in google colab. Our path is `/content/drive/MyDrive/DL_Project/ALBEF`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)\n",
        "print(f'Google Drive Path: {GOOGLE_DRIVE_PATH}')"
      ],
      "metadata": {
        "id": "7vaWO3M8Mmxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246bdcaf-e7e7-49c5-d77a-92f6e64c0d54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive Path: /content/drive/MyDrive/DL_Project/ALBEF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repo to a content\n",
        "!git clone -b main https://github.com/HaixinLiuNeuro/ALBEF.git /tmp/ALBEF\n",
        "!cp -r /tmp/ALBEF/* .\n",
        "!rm -rf /tmp/ALBEF"
      ],
      "metadata": {
        "id": "cj6rXs28G5ck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142beb97-c334-4798-8230-0e84eabda3e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/tmp/ALBEF'...\n",
            "remote: Enumerating objects: 365, done.\u001b[K\n",
            "remote: Counting objects: 100% (220/220), done.\u001b[K\n",
            "remote: Compressing objects: 100% (112/112), done.\u001b[K\n",
            "remote: Total 365 (delta 119), reused 110 (delta 108), pack-reused 145 (from 1)\u001b[K\n",
            "Receiving objects: 100% (365/365), 71.57 MiB | 22.43 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependency\n",
        "!pip install transformers==4.25.1\n",
        "!pip install ruamel.yaml==0.17.*\n",
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N_7q2p11MyGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f468d6-8ec7-4c4b-f9ba-2d0d033be09f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.25.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1)\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2025.1.31)\n",
            "Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.25.1\n",
            "Collecting ruamel.yaml==0.17.*\n",
            "  Downloading ruamel.yaml-0.17.40-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml==0.17.*)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading ruamel.yaml-0.17.40-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml\n",
            "Successfully installed ruamel.yaml-0.17.40 ruamel.yaml.clib-0.2.12\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nQxFlSxfFajH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde2d561-74de-4822-8431-2cea63ee8d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# import\n",
        "import argparse\n",
        "import os\n",
        "import ruamel.yaml as yaml\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "\n",
        "# use vqa model\n",
        "from models.model_vqa import ALBEF\n",
        "\n",
        "from models.vit import interpolate_pos_embed\n",
        "from models.tokenization_bert import BertTokenizer\n",
        "\n",
        "import utils\n",
        "from dataset.utils import save_result\n",
        "from dataset import create_dataset, create_sampler, create_loader, vqa_collate_fn\n",
        "\n",
        "from scheduler import create_scheduler\n",
        "from optim import create_optimizer\n",
        "\n",
        "# print and plotting\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %reload_ext autoreload"
      ],
      "metadata": {
        "id": "JiebcG8heA07"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prep data\n",
        "# download from website\n",
        "\n",
        "# make folder /content/data\n",
        "DATA_PATH = os.path.join('/content', 'data')\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "\n",
        "%cd /content/data\n",
        "\n",
        "# download data from links:\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/json_pretrain.zip\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/data.tar.gz\n",
        "# http://images.cocodataset.org/zips/train2014.zip\n",
        "# http://images.cocodataset.org/zips/val2014.zip\n",
        "# http://images.cocodataset.org/zips/test2015.zip\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the download links\n",
        "links = [\n",
        "    \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/json_pretrain.zip\",\n",
        "    \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/data.tar.gz\",\n",
        "    \"http://images.cocodataset.org/zips/train2014.zip\", # comment out if only run evaluation\n",
        "    \"http://images.cocodataset.org/zips/val2014.zip\",   # comment out if only run evaluation\n",
        "    \"http://images.cocodataset.org/zips/test2015.zip\"\n",
        "]\n",
        "\n",
        "# Download and extract each file\n",
        "for link in links:\n",
        "    filename = link.split('/')[-1]\n",
        "    print(f\"Downloading {filename}...\")\n",
        "\n",
        "    # Download file\n",
        "    !wget -q --show-progress {link}\n",
        "\n",
        "    print(f\"Extracting {filename}...\")\n",
        "\n",
        "    # Extract based on file extension\n",
        "    if filename.endswith('.zip'):\n",
        "      if '//images.cocodataset.org/zips/' in link:\n",
        "        !unzip -q {filename}\n",
        "      else:\n",
        "        !unzip -q -j {filename}  # -j option flattens the directory structure for json_pretrain.zip\n",
        "    elif filename.endswith('.tar.gz'):\n",
        "        !tar -xzf {filename} --strip-components=1  # Remove the top-level directory\n",
        "\n",
        "    # Delete the zip/tar file after extraction\n",
        "    print(f\"Removing {filename}...\")\n",
        "    !rm {filename}\n",
        "\n",
        "    print(f\"Finished processing {filename}\")\n",
        "\n",
        "print(\"All downloads and extractions completed!\")\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "kPxGkhRy4FLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfd9496-3905-4388-f1f2-3fd78c8897f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "Downloading json_pretrain.zip...\n",
            "json_pretrain.zip   100%[===================>] 630.14M   214MB/s    in 2.9s    \n",
            "Extracting json_pretrain.zip...\n",
            "Removing json_pretrain.zip...\n",
            "Finished processing json_pretrain.zip\n",
            "Downloading data.tar.gz...\n",
            "data.tar.gz         100%[===================>] 137.87M   154MB/s    in 0.9s    \n",
            "Extracting data.tar.gz...\n",
            "Removing data.tar.gz...\n",
            "Finished processing data.tar.gz\n",
            "Downloading train2014.zip...\n",
            "train2014.zip       100%[===================>]  12.58G  47.7MB/s    in 4m 7s   \n",
            "Extracting train2014.zip...\n",
            "Removing train2014.zip...\n",
            "Finished processing train2014.zip\n",
            "Downloading val2014.zip...\n",
            "val2014.zip         100%[===================>]   6.19G  40.1MB/s    in 2m 9s   \n",
            "Extracting val2014.zip...\n",
            "Removing val2014.zip...\n",
            "Finished processing val2014.zip\n",
            "Downloading test2015.zip...\n",
            "test2015.zip        100%[===================>]  12.36G  46.0MB/s    in 4m 37s  \n",
            "Extracting test2015.zip...\n",
            "Removing test2015.zip...\n",
            "Finished processing test2015.zip\n",
            "All downloads and extractions completed!\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/data"
      ],
      "metadata": {
        "id": "Sc9XbDXyL4WJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check files\n",
        "%cd /content/data\n",
        "!ls\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "y9cbgfXjUT_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e586c32-7c87-4d55-b8fa-c4cf66b339b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "answer_list.json  flickr30k_test.json\trefcoco+_train.json  ve_train.json\n",
            "cc12m.json\t  flickr30k_train.json\trefcoco+_val.json    vg.json\n",
            "cc3m_train.json   flickr30k_val.json\tsbu.json\t     vg_qa.json\n",
            "cc3m_val.json\t  nlvr_dev.json\t\ttest2015\t     vqa_test_dev.json\n",
            "coco.json\t  nlvr_test.json\ttrain2014\t     vqa_test.json\n",
            "coco_test.json\t  nlvr_train.json\tval2014\t\t     vqa_train.json\n",
            "coco_train.json   refcoco+\t\tve_dev.json\t     vqa_val.json\n",
            "coco_val.json\t  refcoco+_test.json\tve_test.json\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "FETCH_PRETRAINED_MODEL = True\n",
        "%cd /content\n",
        "\n",
        "# download data from links:\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/ALBEF_4M.pth\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/vqa.pth\n",
        "# model check point from training\n",
        "# https://drive.google.com/file/d/1yEsyeB0FkIgWlT2Way_KFLPNLCQy6KoU/view?usp=sharing\n",
        "\n",
        "if FETCH_PRETRAINED_MODEL:\n",
        "\n",
        "  # Define the download links\n",
        "  links = [\n",
        "      \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/ALBEF_4M.pth\",\n",
        "      # \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/vqa.pth\"\n",
        "  ]\n",
        "\n",
        "  # Download and extract each file\n",
        "  for link in links:\n",
        "      filename = link.split('/')[-1]\n",
        "      print(f\"Downloading {filename}...\")\n",
        "\n",
        "      # Download file\n",
        "      !wget -q --show-progress {link}\n",
        "\n",
        "\n",
        "      print(f\"Finished processing {filename}\")\n",
        "\n",
        "  print(\"All model downloads completed!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wWKM1ISxSrPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e9ff52-d3b4-4167-d6cf-b0ddbe2dea2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Downloading ALBEF_4M.pth...\n",
            "ALBEF_4M.pth        100%[===================>]   3.25G   141MB/s    in 25s     \n",
            "Finished processing ALBEF_4M.pth\n",
            "All model downloads completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm5adbe9FajI"
      },
      "source": [
        "## Setup for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1SSGJE2MFajI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7faf6e0-698c-48b5-8bf5-e603bde64fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "{'alpha': 0.4,\n",
            " 'answer_list': 'data/answer_list.json',\n",
            " 'batch_size_test': 16,\n",
            " 'batch_size_train': 32,\n",
            " 'bert_config': 'configs/config_bert.json',\n",
            " 'distill': True,\n",
            " 'eos': '[SEP]',\n",
            " 'image_res': 384,\n",
            " 'k_test': 128,\n",
            " 'optimizer': {'lr': 2e-05, 'opt': 'adamW', 'weight_decay': 0.02},\n",
            " 'schedular': {'cooldown_epochs': 0,\n",
            "               'decay_rate': 1,\n",
            "               'epochs': 8,\n",
            "               'lr': 2e-05,\n",
            "               'min_lr': 1e-06,\n",
            "               'sched': 'cosine',\n",
            "               'warmup_epochs': 4,\n",
            "               'warmup_lr': 1e-05},\n",
            " 'test_file': ['data/vqa_test.json'],\n",
            " 'train_file': ['data/vqa_train.json', 'data/vqa_val.json'],\n",
            " 'vg_root': 'data/',\n",
            " 'vqa_root': 'data/',\n",
            " 'warm_up': True}\n"
          ]
        }
      ],
      "source": [
        "# config\n",
        "%cd /content\n",
        "args = argparse.Namespace()\n",
        "args.config = './configs/VQA.yaml'\n",
        "args.checkpoint = './ALBEF_4M.pth'\n",
        "args.output_dir = 'output/vqa_4MfinetuneVQA'\n",
        "args.evaluate = False # to train use False\n",
        "args.text_encoder = 'bert-base-uncased'\n",
        "args.text_decoder = 'bert-base-uncased'\n",
        "args.device = 'cuda'\n",
        "args.seed = 42\n",
        "args.distributed = False\n",
        "\n",
        "config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)\n",
        "pprint(config)\n",
        "\n",
        "# make result folder and save config\n",
        "args.result_dir = os.path.join(args.output_dir, 'result')\n",
        "\n",
        "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(args.result_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gyGrj0NZFajI"
      },
      "outputs": [],
      "source": [
        "# training functions\n",
        "def train(model, data_loader, optimizer, tokenizer, epoch, warmup_steps, device, scheduler, config):\n",
        "    # train\n",
        "    model.train()\n",
        "\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "    metric_logger.add_meter('loss', utils.SmoothedValue(window_size=1, fmt='{value:.4f}'))\n",
        "\n",
        "    header = 'Train Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    step_size = 100\n",
        "    warmup_iterations = warmup_steps*step_size\n",
        "\n",
        "    for i,(image, question, answer, weights, n) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        image, weights = image.to(device,non_blocking=True), weights.to(device,non_blocking=True)\n",
        "        question_input = tokenizer(question, padding='longest', truncation=True, max_length=25, return_tensors=\"pt\").to(device)\n",
        "        answer_input = tokenizer(answer, padding='longest', return_tensors=\"pt\").to(device)\n",
        "\n",
        "        if epoch>0 or not config['warm_up']:\n",
        "            alpha = config['alpha']\n",
        "        else:\n",
        "            alpha = config['alpha']*min(1,i/len(data_loader))\n",
        "\n",
        "        loss = model(image, question_input, answer_input, train=True, alpha=alpha, k=n, weights=weights)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        metric_logger.update(loss=loss.item())\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "        if epoch==0 and i%step_size==0 and i<=warmup_iterations:\n",
        "            scheduler.step(i//step_size)\n",
        "\n",
        "    # gather the stats from all processes\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger.global_avg())\n",
        "    return {k: \"{:.3f}\".format(meter.global_avg) for k, meter in metric_logger.meters.items()}\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluation(model, data_loader, tokenizer, device, config) :\n",
        "    # test\n",
        "    model.eval()\n",
        "\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = 'Generate VQA test result:'\n",
        "    print_freq = 50\n",
        "\n",
        "    result = []\n",
        "\n",
        "    answer_list = [answer+config['eos'] for answer in data_loader.dataset.answer_list]\n",
        "    answer_input = tokenizer(answer_list, padding='longest', return_tensors='pt').to(device)\n",
        "\n",
        "    for n, (image, question, question_id) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        image = image.to(device,non_blocking=True)\n",
        "        question_input = tokenizer(question, padding='longest', return_tensors=\"pt\").to(device)\n",
        "\n",
        "        topk_ids, topk_probs = model(image, question_input, answer_input, train=False, k=config['k_test'])\n",
        "\n",
        "        for ques_id, topk_id, topk_prob in zip(question_id, topk_ids, topk_probs):\n",
        "            ques_id = int(ques_id.item())\n",
        "            _, pred = topk_prob.max(dim=0)\n",
        "            result.append({\"question_id\":ques_id, \"answer\":data_loader.dataset.answer_list[topk_id[pred]]})\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "O_fo-oPwFajI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b3ee99-4c96-475d-e5d8-1079ca39a1c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# setup for training/evaluation (from main)\n",
        "utils.init_distributed_mode(args)\n",
        "\n",
        "device = torch.device(args.device)\n",
        "print(f'device: {device}')\n",
        "\n",
        "# fix the seed for reproducibility\n",
        "seed = args.seed + utils.get_rank()\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "start_epoch = 0\n",
        "max_epoch = config['schedular']['epochs']\n",
        "warmup_steps = config['schedular']['warmup_epochs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lmtKe-XVFajI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "7b2bac2e1eb44a84a7e84f02a3084fc4",
            "8cf5279033e04a0a9215ed257308fd0b",
            "da2aa7b3cce540fea2099c359c7ec6e5",
            "9498305399a64bbbb90dcf16ee5a75a4",
            "a2ccbd2604134042866029bad09f4087",
            "b8300b2367e64ad7a6dbdb9c267bc4ef",
            "49070f6fbbd746d1855884157e3e7bd0",
            "45f14539873b48ee89a2f8cecf38cf92",
            "20a7e90af8274064a462832b3126c852",
            "a66a620030f94cc2a97e6487cd6d93f4",
            "faf6f478b6284d71b74db7b1f669de3f",
            "4589ea0503ed4556a790fb244e074e22",
            "413f4d8b52ef49b98d29e5c0fa9a91d3",
            "ad78cc52a93d48b69848ef095cf97248",
            "f5d6771242c0433ea0d9b99c48634598",
            "0a49c509948243dda5a1c1c76e6bf3ab",
            "63ee16fce60246d4a623c92d562f6cb1",
            "1a1dc47858994bc6a59d9ac73cd80a63",
            "6ef6ea45fbb34fc8a7b4a57360f70c17",
            "92971884456d4870abdded1593941785",
            "ea27d7392fad474da9fa20052e4783f3",
            "1844540bdce747fcb3073bfb77ba5f14",
            "af367143b38e4d8f9c0be272871b9250",
            "c1e59b15bb7248df971c4b25d263e1b3",
            "73d1530693ab43f3bc673fba11244681",
            "270a76bfdc274e81bf3c5dd557262471",
            "b644567ee62a4a34b67f7b946240f567",
            "21e228092b404716b45743fb44b7e503",
            "774dee98d556424bae3bc6147ea01ce2",
            "9a046d868f264ab3b26b6135d75debe2",
            "f55e6bd8568648d186605b682490b228",
            "683177e228dc4dbd81923b4694e9f36e",
            "d19f0f3028014a518d51ec613ef052d4"
          ]
        },
        "outputId": "66cfd724-0ff5-4788-ef8b-01eb339af556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating vqa datasets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b2bac2e1eb44a84a7e84f02a3084fc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4589ea0503ed4556a790fb244e074e22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af367143b38e4d8f9c0be272871b9250"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# make dataset and dataloader\n",
        "print(\"Creating vqa datasets\")\n",
        "datasets = create_dataset('vqa', config)\n",
        "\n",
        "if args.distributed:\n",
        "    num_tasks = utils.get_world_size()\n",
        "    global_rank = utils.get_rank()\n",
        "    samplers = create_sampler(datasets, [True, False], num_tasks, global_rank)\n",
        "else:\n",
        "    samplers = [None, None]\n",
        "\n",
        "train_loader, test_loader = create_loader(datasets,samplers,\n",
        "                                          batch_size=[config['batch_size_train'],config['batch_size_test']],\n",
        "                                          num_workers=[4,4],is_trains=[True, False],\n",
        "                                          collate_fns=[vqa_collate_fn,None])\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(args.text_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6zYcjMhhFajI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e2c08a206cac4fbb952063991511c772",
            "bc9211b6d06546c589c46e63d9f7a760",
            "db53f650a2d34a18968a249b6cdfa47f",
            "f6bd621809c9459fb521b0fa5e9600ce",
            "7ceab4854dd14639a619053495a5b5dc",
            "d17d570910fc4d96aee4cc815024d5d8",
            "30d27606beee4e61b81b33cd46525b66",
            "3527665eb00e4ebdbd84b37d78c5d876",
            "6fa3542c33b34935a30fc8cd30a95a00",
            "13ab7496ca87401cb07e962fad6a1ff4",
            "613bdc17f14b4a18be88b278c27b5ecf"
          ]
        },
        "outputId": "497b55f4-d2f8-431d-bf01-6c371fcbd69d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2c08a206cac4fbb952063991511c772"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ALBEF(\n",
              "  (visual_encoder): VisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      (norm): Identity()\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (text_encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6-11): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (text_decoder): BertLMHeadModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-5): 6 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (visual_encoder_m): VisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      (norm): Identity()\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (text_encoder_m): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6-11): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (text_decoder_m): BertLMHeadModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-5): 6 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#### Model ####\n",
        "print(\"Creating model\")\n",
        "model = ALBEF(config=config, text_encoder=args.text_encoder, text_decoder=args.text_decoder, tokenizer=tokenizer)\n",
        "model = model.to(device)\n",
        "\n",
        "arg_opt = utils.AttrDict(config['optimizer'])\n",
        "optimizer = create_optimizer(arg_opt, model)\n",
        "arg_sche = utils.AttrDict(config['schedular'])\n",
        "lr_scheduler, _ = create_scheduler(arg_sche, optimizer)\n",
        "\n",
        "# check model\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B64EarwbFajJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de566680-f95b-4c11-b6d7-cb5683e8e43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reshape position embedding from 256 to 576\n",
            "reshape position embedding from 256 to 576\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '0', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '1', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '2', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '3', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '4', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '5', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '6', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '7', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '8', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '9', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '10', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'output', 'dense', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'output', 'dense', 'bias']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder', 'bert', 'encoder', 'layer', '11', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '0', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '1', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '2', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '3', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '4', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '5', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '6', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '7', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '8', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '9', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '10', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'attention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'query', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'query', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'key', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'key', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'value', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'self', 'value', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'crossattention', 'output', 'LayerNorm', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'intermediate', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'intermediate', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'output', 'dense', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'output', 'dense', 'bias']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'output', 'LayerNorm', 'weight']\n",
            "['text_encoder_m', 'bert', 'encoder', 'layer', '11', 'output', 'LayerNorm', 'bias']\n",
            "load checkpoint from ./ALBEF_4M.pth\n",
            "_IncompatibleKeys(missing_keys=[], unexpected_keys=['temp', 'image_queue', 'text_queue', 'queue_ptr', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias', 'vision_proj_m.weight', 'vision_proj_m.bias', 'text_proj_m.weight', 'text_proj_m.bias'])\n"
          ]
        }
      ],
      "source": [
        "# load check point to continue training\n",
        "if args.checkpoint:\n",
        "    checkpoint = torch.load(args.checkpoint, map_location='cpu')\n",
        "    if args.evaluate:\n",
        "        state_dict = checkpoint\n",
        "    else:\n",
        "        state_dict = checkpoint['model']\n",
        "\n",
        "    # reshape positional embedding to accomodate for image resolution change\n",
        "    pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder.pos_embed'],model.visual_encoder)\n",
        "    state_dict['visual_encoder.pos_embed'] = pos_embed_reshaped\n",
        "    # # Check if the key exists before accessing it\n",
        "    # if 'visual_encoder.pos_embed' in state_dict:\n",
        "    #     # reshape positional embedding to accomodate for image resolution change\n",
        "    #     pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder.pos_embed'],model.visual_encoder)\n",
        "    #     state_dict['visual_encoder.pos_embed'] = pos_embed_reshaped\n",
        "    # else:\n",
        "    #     print(\"Warning: 'visual_encoder.pos_embed' not found in checkpoint. Skipping positional embedding interpolation.\")\n",
        "\n",
        "\n",
        "    if not args.evaluate:\n",
        "        if config['distill']:\n",
        "            m_pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder_m.pos_embed'],model.visual_encoder_m)\n",
        "            state_dict['visual_encoder_m.pos_embed'] = m_pos_embed_reshaped\n",
        "\n",
        "        for key in list(state_dict.keys()):\n",
        "            if 'bert' in key:\n",
        "                encoder_key = key.replace('bert.','')\n",
        "                state_dict[encoder_key] = state_dict[key]\n",
        "            # intialize text decoder as multimodal encoder (last 6 layers of model.text_encoder)\n",
        "            if 'text_encoder' in key:\n",
        "                if 'layer' in key:\n",
        "                    # print(key)\n",
        "                    encoder_keys = key.split('.')\n",
        "                    print(encoder_keys)\n",
        "                    # print(encoder_keys[4])\n",
        "                    tmp_fix_idx = 4 # for the downsized model, idx 5 is the layer number\n",
        "                    layer_num = int(encoder_keys[tmp_fix_idx]) # 4\n",
        "                    if layer_num<6:\n",
        "                        del state_dict[key]\n",
        "                        continue\n",
        "                    else:\n",
        "                        decoder_layer_num = (layer_num-6)\n",
        "                        encoder_keys[4] = str(decoder_layer_num)\n",
        "                        encoder_key = '.'.join(encoder_keys)\n",
        "                else:\n",
        "                    encoder_key = key\n",
        "                decoder_key = encoder_key.replace('text_encoder','text_decoder')\n",
        "                state_dict[decoder_key] = state_dict[key]\n",
        "\n",
        "                del state_dict[key]\n",
        "\n",
        "    msg = model.load_state_dict(state_dict,strict=False)\n",
        "    print('load checkpoint from %s'%args.checkpoint)\n",
        "    print(msg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VJmSxRhtFajJ"
      },
      "outputs": [],
      "source": [
        "# handle distributed training\n",
        "model_without_ddp = model\n",
        "if args.distributed:\n",
        "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
        "    model_without_ddp = model.module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VyQyvZE1FajJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "a26ac0bb-0f90-40d3-d8c6-0d88136a4900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n",
            "/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n",
            "  offset = -low * scale\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 38.12 MiB is free. Process 10381 has 14.70 GiB memory in use. Of the allocated memory 14.23 GiB is allocated by PyTorch, and 351.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b4454c9887d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-bf7e35e8c1eb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer, tokenizer, epoch, warmup_steps, device, scheduler, config)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/model_vqa.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, quesiton, answer, alpha, k, weights, train)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquesiton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mimage_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mimage_atts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, register_blk)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_blk\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, register_hook)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/models/vit.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, register_hook)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqkv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# make torchscript happy (cannot use tensor as tuple)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 38.12 MiB is free. Process 10381 has 14.70 GiB memory in use. Of the allocated memory 14.23 GiB is allocated by PyTorch, and 351.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# training loop, single GPU\n",
        "print(\"Start training\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(start_epoch, max_epoch):\n",
        "    if epoch>0:\n",
        "        lr_scheduler.step(epoch+warmup_steps)\n",
        "\n",
        "    if not args.evaluate:\n",
        "        if args.distributed:\n",
        "            train_loader.sampler.set_epoch(epoch)\n",
        "\n",
        "        train_stats = train(model, train_loader, optimizer, tokenizer, epoch, warmup_steps, device, lr_scheduler, config)\n",
        "\n",
        "    if args.evaluate:\n",
        "        break\n",
        "\n",
        "    if utils.is_main_process():\n",
        "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
        "                      'epoch': epoch,\n",
        "                    }\n",
        "        with open(os.path.join(args.output_dir, \"log.txt\"),\"a\") as f:\n",
        "            f.write(json.dumps(log_stats) + \"\\n\")\n",
        "\n",
        "        save_obj = {\n",
        "            'model': model_without_ddp.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'lr_scheduler': lr_scheduler.state_dict(),\n",
        "            'config': config,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        torch.save(save_obj, os.path.join(args.output_dir, 'checkpoint_%02d.pth'%epoch))\n",
        "    if args.distributed:\n",
        "        dist.barrier()\n",
        "    else:\n",
        "        pass  # Skip barrier for non-distributed training\n",
        "\n",
        "# evaluation\n",
        "vqa_result = evaluation(model, test_loader, tokenizer, device, config)\n",
        "result_file = save_result(vqa_result, args.result_dir, 'vqa_result_epoch%d'%epoch)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print('Time time {}'.format(total_time_str))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_DRIVE_PATH"
      ],
      "metadata": {
        "id": "T52hIhCtaoJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save result to google drive\n",
        "!cp -r {args.output_dir} {GOOGLE_DRIVE_PATH}"
      ],
      "metadata": {
        "id": "qmVYMgYzgka2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b2bac2e1eb44a84a7e84f02a3084fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cf5279033e04a0a9215ed257308fd0b",
              "IPY_MODEL_da2aa7b3cce540fea2099c359c7ec6e5",
              "IPY_MODEL_9498305399a64bbbb90dcf16ee5a75a4"
            ],
            "layout": "IPY_MODEL_a2ccbd2604134042866029bad09f4087"
          }
        },
        "8cf5279033e04a0a9215ed257308fd0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8300b2367e64ad7a6dbdb9c267bc4ef",
            "placeholder": "​",
            "style": "IPY_MODEL_49070f6fbbd746d1855884157e3e7bd0",
            "value": "vocab.txt: 100%"
          }
        },
        "da2aa7b3cce540fea2099c359c7ec6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f14539873b48ee89a2f8cecf38cf92",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20a7e90af8274064a462832b3126c852",
            "value": 231508
          }
        },
        "9498305399a64bbbb90dcf16ee5a75a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a66a620030f94cc2a97e6487cd6d93f4",
            "placeholder": "​",
            "style": "IPY_MODEL_faf6f478b6284d71b74db7b1f669de3f",
            "value": " 232k/232k [00:00&lt;00:00, 1.71MB/s]"
          }
        },
        "a2ccbd2604134042866029bad09f4087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8300b2367e64ad7a6dbdb9c267bc4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49070f6fbbd746d1855884157e3e7bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45f14539873b48ee89a2f8cecf38cf92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a7e90af8274064a462832b3126c852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a66a620030f94cc2a97e6487cd6d93f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf6f478b6284d71b74db7b1f669de3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4589ea0503ed4556a790fb244e074e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_413f4d8b52ef49b98d29e5c0fa9a91d3",
              "IPY_MODEL_ad78cc52a93d48b69848ef095cf97248",
              "IPY_MODEL_f5d6771242c0433ea0d9b99c48634598"
            ],
            "layout": "IPY_MODEL_0a49c509948243dda5a1c1c76e6bf3ab"
          }
        },
        "413f4d8b52ef49b98d29e5c0fa9a91d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63ee16fce60246d4a623c92d562f6cb1",
            "placeholder": "​",
            "style": "IPY_MODEL_1a1dc47858994bc6a59d9ac73cd80a63",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ad78cc52a93d48b69848ef095cf97248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef6ea45fbb34fc8a7b4a57360f70c17",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92971884456d4870abdded1593941785",
            "value": 48
          }
        },
        "f5d6771242c0433ea0d9b99c48634598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea27d7392fad474da9fa20052e4783f3",
            "placeholder": "​",
            "style": "IPY_MODEL_1844540bdce747fcb3073bfb77ba5f14",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.04kB/s]"
          }
        },
        "0a49c509948243dda5a1c1c76e6bf3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ee16fce60246d4a623c92d562f6cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a1dc47858994bc6a59d9ac73cd80a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef6ea45fbb34fc8a7b4a57360f70c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92971884456d4870abdded1593941785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea27d7392fad474da9fa20052e4783f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1844540bdce747fcb3073bfb77ba5f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af367143b38e4d8f9c0be272871b9250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1e59b15bb7248df971c4b25d263e1b3",
              "IPY_MODEL_73d1530693ab43f3bc673fba11244681",
              "IPY_MODEL_270a76bfdc274e81bf3c5dd557262471"
            ],
            "layout": "IPY_MODEL_b644567ee62a4a34b67f7b946240f567"
          }
        },
        "c1e59b15bb7248df971c4b25d263e1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21e228092b404716b45743fb44b7e503",
            "placeholder": "​",
            "style": "IPY_MODEL_774dee98d556424bae3bc6147ea01ce2",
            "value": "config.json: 100%"
          }
        },
        "73d1530693ab43f3bc673fba11244681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a046d868f264ab3b26b6135d75debe2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f55e6bd8568648d186605b682490b228",
            "value": 570
          }
        },
        "270a76bfdc274e81bf3c5dd557262471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_683177e228dc4dbd81923b4694e9f36e",
            "placeholder": "​",
            "style": "IPY_MODEL_d19f0f3028014a518d51ec613ef052d4",
            "value": " 570/570 [00:00&lt;00:00, 46.7kB/s]"
          }
        },
        "b644567ee62a4a34b67f7b946240f567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e228092b404716b45743fb44b7e503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "774dee98d556424bae3bc6147ea01ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a046d868f264ab3b26b6135d75debe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55e6bd8568648d186605b682490b228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "683177e228dc4dbd81923b4694e9f36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d19f0f3028014a518d51ec613ef052d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2c08a206cac4fbb952063991511c772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc9211b6d06546c589c46e63d9f7a760",
              "IPY_MODEL_db53f650a2d34a18968a249b6cdfa47f",
              "IPY_MODEL_f6bd621809c9459fb521b0fa5e9600ce"
            ],
            "layout": "IPY_MODEL_7ceab4854dd14639a619053495a5b5dc"
          }
        },
        "bc9211b6d06546c589c46e63d9f7a760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d17d570910fc4d96aee4cc815024d5d8",
            "placeholder": "​",
            "style": "IPY_MODEL_30d27606beee4e61b81b33cd46525b66",
            "value": "model.safetensors: 100%"
          }
        },
        "db53f650a2d34a18968a249b6cdfa47f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3527665eb00e4ebdbd84b37d78c5d876",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fa3542c33b34935a30fc8cd30a95a00",
            "value": 440449768
          }
        },
        "f6bd621809c9459fb521b0fa5e9600ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13ab7496ca87401cb07e962fad6a1ff4",
            "placeholder": "​",
            "style": "IPY_MODEL_613bdc17f14b4a18be88b278c27b5ecf",
            "value": " 440M/440M [00:01&lt;00:00, 152MB/s]"
          }
        },
        "7ceab4854dd14639a619053495a5b5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d17d570910fc4d96aee4cc815024d5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30d27606beee4e61b81b33cd46525b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3527665eb00e4ebdbd84b37d78c5d876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa3542c33b34935a30fc8cd30a95a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13ab7496ca87401cb07e962fad6a1ff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "613bdc17f14b4a18be88b278c27b5ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
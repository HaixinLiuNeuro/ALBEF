{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaixinLiuNeuro/ALBEF/blob/main/colab_load_noPretrain_noFineTuen_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24nSaNVhFajG"
      },
      "source": [
        "# no pretrained 4M model, without fine-tune with only VQA dataset, run evaluation test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "jpeIswepIcEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbb5047-07d3-4b5a-c073-184e3297e70f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup drive folder\n",
        "import os\n",
        "\n",
        "# TODO: Fill in the Google Drive path where you want to save result\n",
        "GOOGLE_DRIVE_PATH_POST_MYDRIVE = os.path.join('DL_Project', 'ALBEF')\n",
        "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
        "os.makedirs(GOOGLE_DRIVE_PATH, exist_ok=True)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))"
      ],
      "metadata": {
        "id": "-C2cjy7sLsaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bcffef0-5d4e-437a-9bd1-eded9fac1ff3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['output', 'vqa_end2end', 'vqa_onlyPretrainModel']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if running locally set GOOGLE PATH\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
        "else:\n",
        "  GOOGLE_DRIVE_PATH = '.'\n",
        "  print('Running locally.')"
      ],
      "metadata": {
        "id": "3gnMy6WHMjZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a28a3c-45ab-4f71-b162-467ff3e572df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in google colab. Our path is `/content/drive/MyDrive/DL_Project/ALBEF`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)\n",
        "print(f'Google Drive Path: {GOOGLE_DRIVE_PATH}')"
      ],
      "metadata": {
        "id": "7vaWO3M8Mmxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e63714-b3d2-48ca-8fec-3f2fadfbe6d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive Path: /content/drive/MyDrive/DL_Project/ALBEF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repo to a content\n",
        "!git clone -b main https://github.com/HaixinLiuNeuro/ALBEF.git /tmp/ALBEF\n",
        "!cp -r /tmp/ALBEF/* .\n",
        "!rm -rf /tmp/ALBEF"
      ],
      "metadata": {
        "id": "cj6rXs28G5ck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1a185f-24fa-4b5d-c177-44efb5e8dd3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/tmp/ALBEF'...\n",
            "remote: Enumerating objects: 388, done.\u001b[K\n",
            "remote: Counting objects: 100% (243/243), done.\u001b[K\n",
            "remote: Compressing objects: 100% (131/131), done.\u001b[K\n",
            "remote: Total 388 (delta 137), reused 117 (delta 112), pack-reused 145 (from 1)\u001b[K\n",
            "Receiving objects: 100% (388/388), 71.60 MiB | 60.00 MiB/s, done.\n",
            "Resolving deltas: 100% (159/159), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependency\n",
        "!pip install transformers==4.25.1\n",
        "!pip install ruamel.yaml==0.17.*\n",
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N_7q2p11MyGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096f56a6-f0c9-4a66-da3a-bbba7ebe1588"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.25.1\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1)\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2025.1.31)\n",
            "Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m142.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.25.1\n",
            "Collecting ruamel.yaml==0.17.*\n",
            "  Downloading ruamel.yaml-0.17.40-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml==0.17.*)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading ruamel.yaml-0.17.40-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml\n",
            "Successfully installed ruamel.yaml-0.17.40 ruamel.yaml.clib-0.2.12\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nQxFlSxfFajH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24acb2c-4dbe-45b9-8c49-f554a45a5c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# import\n",
        "import argparse\n",
        "import os\n",
        "import ruamel.yaml as yaml\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.distributed as dist\n",
        "\n",
        "# use vqa model\n",
        "from models.model_vqa import ALBEF\n",
        "\n",
        "from models.vit import interpolate_pos_embed\n",
        "from models.tokenization_bert import BertTokenizer\n",
        "\n",
        "import utils\n",
        "from dataset.utils import save_result\n",
        "from dataset import create_dataset, create_sampler, create_loader, vqa_collate_fn\n",
        "\n",
        "from scheduler import create_scheduler\n",
        "from optim import create_optimizer\n",
        "\n",
        "# print and plotting\n",
        "from pprint import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %reload_ext autoreload"
      ],
      "metadata": {
        "id": "JiebcG8heA07"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prep data\n",
        "# download from website\n",
        "\n",
        "# make folder /content/data\n",
        "DATA_PATH = os.path.join('/content', 'data')\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "\n",
        "%cd /content/data\n",
        "\n",
        "# download data from links:\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/json_pretrain.zip\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/data.tar.gz\n",
        "# http://images.cocodataset.org/zips/train2014.zip\n",
        "# http://images.cocodataset.org/zips/val2014.zip\n",
        "# http://images.cocodataset.org/zips/test2015.zip\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the download links\n",
        "links = [\n",
        "    # \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/json_pretrain.zip\", # pretrain json\n",
        "    \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/data.tar.gz\", # for downstream task json\n",
        "    # \"http://images.cocodataset.org/zips/train2014.zip\", # comment out if only run evaluation\n",
        "    # \"http://images.cocodataset.org/zips/val2014.zip\",   # comment out if only run evaluation\n",
        "    \"http://images.cocodataset.org/zips/test2015.zip\"\n",
        "]\n",
        "\n",
        "# Download and extract each file\n",
        "for link in links:\n",
        "    filename = link.split('/')[-1]\n",
        "    print(f\"Downloading {filename}...\")\n",
        "\n",
        "    # Download file\n",
        "    !wget -q --show-progress {link}\n",
        "\n",
        "    print(f\"Extracting {filename}...\")\n",
        "\n",
        "    # Extract based on file extension\n",
        "    if filename.endswith('.zip'):\n",
        "      if '//images.cocodataset.org/zips/' in link:\n",
        "        !unzip -q {filename}\n",
        "      else:\n",
        "        !unzip -q -j {filename}  # -j option flattens the directory structure for json_pretrain.zip\n",
        "    elif filename.endswith('.tar.gz'):\n",
        "        !tar -xzf {filename} --strip-components=1  # Remove the top-level directory\n",
        "\n",
        "    # Delete the zip/tar file after extraction\n",
        "    print(f\"Removing {filename}...\")\n",
        "    !rm {filename}\n",
        "\n",
        "    print(f\"Finished processing {filename}\")\n",
        "\n",
        "print(\"All downloads and extractions completed!\")\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "kPxGkhRy4FLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3bbdf0-a9cd-485a-b471-04e7219deae3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "Downloading data.tar.gz...\n",
            "data.tar.gz         100%[===================>] 137.87M   170MB/s    in 0.8s    \n",
            "Extracting data.tar.gz...\n",
            "Removing data.tar.gz...\n",
            "Finished processing data.tar.gz\n",
            "Downloading test2015.zip...\n",
            "test2015.zip        100%[===================>]  12.36G  43.7MB/s    in 7m 46s  \n",
            "Extracting test2015.zip...\n",
            "Removing test2015.zip...\n",
            "Finished processing test2015.zip\n",
            "All downloads and extractions completed!\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/data"
      ],
      "metadata": {
        "id": "Sc9XbDXyL4WJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check files\n",
        "%cd /content/data\n",
        "!ls\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "y9cbgfXjUT_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1210e83e-75ca-4da2-8696-2058292e8e2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "answer_list.json      nlvr_test.json\t   ve_test.json\n",
            "coco_test.json\t      nlvr_train.json\t   ve_train.json\n",
            "coco_train.json       refcoco+\t\t   vg_qa.json\n",
            "coco_val.json\t      refcoco+_test.json   vqa_test_dev.json\n",
            "flickr30k_test.json   refcoco+_train.json  vqa_test.json\n",
            "flickr30k_train.json  refcoco+_val.json    vqa_train.json\n",
            "flickr30k_val.json    test2015\t\t   vqa_val.json\n",
            "nlvr_dev.json\t      ve_dev.json\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "FETCH_PRETRAINED_MODEL = False\n",
        "%cd /content\n",
        "\n",
        "# download data from links:\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/ALBEF_4M.pth\n",
        "# https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/vqa.pth\n",
        "# model check point from training\n",
        "# https://drive.google.com/file/d/1yEsyeB0FkIgWlT2Way_KFLPNLCQy6KoU/view?usp=sharing\n",
        "\n",
        "if FETCH_PRETRAINED_MODEL:\n",
        "\n",
        "  # Define the download links\n",
        "  links = [\n",
        "      \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/ALBEF_4M.pth\",\n",
        "      # \"https://storage.googleapis.com/sfr-pcl-data-research/ALBEF/vqa.pth\"\n",
        "  ]\n",
        "\n",
        "  # Download and extract each file\n",
        "  for link in links:\n",
        "      filename = link.split('/')[-1]\n",
        "      print(f\"Downloading {filename}...\")\n",
        "\n",
        "      # Download file\n",
        "      !wget -q --show-progress {link}\n",
        "\n",
        "\n",
        "      print(f\"Finished processing {filename}\")\n",
        "\n",
        "  print(\"All model downloads completed!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wWKM1ISxSrPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c684053b-a8a6-4e9c-c99c-599361cedef0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm5adbe9FajI"
      },
      "source": [
        "## Setup for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1SSGJE2MFajI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098cca59-b62c-4532-9fdf-ac0f28141a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "{'alpha': 0.4,\n",
            " 'answer_list': 'data/answer_list.json',\n",
            " 'batch_size_test': 80,\n",
            " 'batch_size_train': 32,\n",
            " 'bert_config': 'configs/config_bert.json',\n",
            " 'distill': True,\n",
            " 'eos': '[SEP]',\n",
            " 'image_res': 384,\n",
            " 'k_test': 128,\n",
            " 'optimizer': {'lr': 2e-05, 'opt': 'adamW', 'weight_decay': 0.02},\n",
            " 'schedular': {'cooldown_epochs': 0,\n",
            "               'decay_rate': 1,\n",
            "               'epochs': 8,\n",
            "               'lr': 2e-05,\n",
            "               'min_lr': 1e-06,\n",
            "               'sched': 'cosine',\n",
            "               'warmup_epochs': 4,\n",
            "               'warmup_lr': 1e-05},\n",
            " 'test_file': ['data/vqa_test.json'],\n",
            " 'train_file': ['data/vqa_train.json', 'data/vqa_val.json'],\n",
            " 'vg_root': 'data/',\n",
            " 'vqa_root': 'data/',\n",
            " 'warm_up': True}\n"
          ]
        }
      ],
      "source": [
        "# config\n",
        "%cd /content\n",
        "args = argparse.Namespace()\n",
        "args.config = './configs/VQA_biggerTestBatch.yaml'\n",
        "args.checkpoint = '' #'./ALBEF_4M.pth'\n",
        "args.output_dir = 'output/vqa_nopretrain_noTune'\n",
        "args.evaluate = True # to train use False\n",
        "args.text_encoder = 'bert-base-uncased'\n",
        "args.text_decoder = 'bert-base-uncased'\n",
        "args.device = 'cuda'\n",
        "args.seed = 42\n",
        "args.distributed = False\n",
        "\n",
        "config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)\n",
        "pprint(config)\n",
        "\n",
        "# make result folder and save config\n",
        "args.result_dir = os.path.join(args.output_dir, 'result')\n",
        "\n",
        "Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
        "Path(args.result_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gyGrj0NZFajI"
      },
      "outputs": [],
      "source": [
        "# training functions\n",
        "def train(model, data_loader, optimizer, tokenizer, epoch, warmup_steps, device, scheduler, config):\n",
        "    # train\n",
        "    model.train()\n",
        "\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "    metric_logger.add_meter('loss', utils.SmoothedValue(window_size=1, fmt='{value:.4f}'))\n",
        "\n",
        "    header = 'Train Epoch: [{}]'.format(epoch)\n",
        "    print_freq = 50\n",
        "    step_size = 100\n",
        "    warmup_iterations = warmup_steps*step_size\n",
        "\n",
        "    for i,(image, question, answer, weights, n) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        image, weights = image.to(device,non_blocking=True), weights.to(device,non_blocking=True)\n",
        "        question_input = tokenizer(question, padding='longest', truncation=True, max_length=25, return_tensors=\"pt\").to(device)\n",
        "        answer_input = tokenizer(answer, padding='longest', return_tensors=\"pt\").to(device)\n",
        "\n",
        "        if epoch>0 or not config['warm_up']:\n",
        "            alpha = config['alpha']\n",
        "        else:\n",
        "            alpha = config['alpha']*min(1,i/len(data_loader))\n",
        "\n",
        "        loss = model(image, question_input, answer_input, train=True, alpha=alpha, k=n, weights=weights)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        metric_logger.update(loss=loss.item())\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "        if epoch==0 and i%step_size==0 and i<=warmup_iterations:\n",
        "            scheduler.step(i//step_size)\n",
        "\n",
        "    # gather the stats from all processes\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger.global_avg())\n",
        "    return {k: \"{:.3f}\".format(meter.global_avg) for k, meter in metric_logger.meters.items()}\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluation(model, data_loader, tokenizer, device, config) :\n",
        "    # test\n",
        "    model.eval()\n",
        "\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = 'Generate VQA test result:'\n",
        "    print_freq = 50\n",
        "\n",
        "    result = []\n",
        "\n",
        "    answer_list = [answer+config['eos'] for answer in data_loader.dataset.answer_list]\n",
        "    answer_input = tokenizer(answer_list, padding='longest', return_tensors='pt').to(device)\n",
        "\n",
        "    for n, (image, question, question_id) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        image = image.to(device,non_blocking=True)\n",
        "        question_input = tokenizer(question, padding='longest', return_tensors=\"pt\").to(device)\n",
        "\n",
        "        topk_ids, topk_probs = model(image, question_input, answer_input, train=False, k=config['k_test'])\n",
        "\n",
        "        for ques_id, topk_id, topk_prob in zip(question_id, topk_ids, topk_probs):\n",
        "            ques_id = int(ques_id.item())\n",
        "            _, pred = topk_prob.max(dim=0)\n",
        "            result.append({\"question_id\":ques_id, \"answer\":data_loader.dataset.answer_list[topk_id[pred]]})\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "O_fo-oPwFajI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa07cb04-f07c-4ae8-ca54-6cd64e4aef9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "# setup for training/evaluation (from main)\n",
        "utils.init_distributed_mode(args)\n",
        "\n",
        "device = torch.device(args.device)\n",
        "print(f'device: {device}')\n",
        "\n",
        "# fix the seed for reproducibility\n",
        "seed = args.seed + utils.get_rank()\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "start_epoch = 0\n",
        "max_epoch = config['schedular']['epochs']\n",
        "warmup_steps = config['schedular']['warmup_epochs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lmtKe-XVFajI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7200c3f3-8e5f-4a99-85c1-cfc4c8d4f1dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating vqa datasets\n"
          ]
        }
      ],
      "source": [
        "# make dataset and dataloader\n",
        "print(\"Creating vqa datasets\")\n",
        "datasets = create_dataset('vqa', config)\n",
        "\n",
        "if args.distributed:\n",
        "    num_tasks = utils.get_world_size()\n",
        "    global_rank = utils.get_rank()\n",
        "    samplers = create_sampler(datasets, [True, False], num_tasks, global_rank)\n",
        "else:\n",
        "    samplers = [None, None]\n",
        "\n",
        "train_loader, test_loader = create_loader(datasets,samplers,\n",
        "                                          batch_size=[config['batch_size_train'],config['batch_size_test']],\n",
        "                                          num_workers=[4,4],is_trains=[True, False],\n",
        "                                          collate_fns=[vqa_collate_fn,None])\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(args.text_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6zYcjMhhFajI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab111c6-6952-48c5-b521-7f4fbf4f2e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ALBEF(\n",
              "  (visual_encoder): VisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      (norm): Identity()\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (text_encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6-11): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (text_decoder): BertLMHeadModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-5): 6 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (visual_encoder_m): VisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      (norm): Identity()\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x Block(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (text_encoder_m): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6-11): 6 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (text_decoder_m): BertLMHeadModel(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-5): 6 x BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (crossattention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (cls): BertOnlyMLMHead(\n",
              "      (predictions): BertLMPredictionHead(\n",
              "        (transform): BertPredictionHeadTransform(\n",
              "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (transform_act_fn): GELUActivation()\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#### Model ####\n",
        "print(\"Creating model\")\n",
        "model = ALBEF(config=config, text_encoder=args.text_encoder, text_decoder=args.text_decoder, tokenizer=tokenizer)\n",
        "model = model.to(device)\n",
        "\n",
        "arg_opt = utils.AttrDict(config['optimizer'])\n",
        "optimizer = create_optimizer(arg_opt, model)\n",
        "arg_sche = utils.AttrDict(config['schedular'])\n",
        "lr_scheduler, _ = create_scheduler(arg_sche, optimizer)\n",
        "\n",
        "# check model\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: clean GPU RAM\n",
        "\n",
        "# import torch\n",
        "\n",
        "# def clean_gpu_memory():\n",
        "#   \"\"\"Clears the GPU memory cache.\"\"\"\n",
        "#   torch.cuda.empty_cache()\n",
        "\n",
        "# clean_gpu_memory()\n"
      ],
      "metadata": {
        "id": "dTkjQqYgccRu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "B64EarwbFajJ"
      },
      "outputs": [],
      "source": [
        "# load check point to continue training\n",
        "if args.checkpoint:\n",
        "    checkpoint = torch.load(args.checkpoint, map_location='cpu')\n",
        "    if args.evaluate:\n",
        "        state_dict = checkpoint\n",
        "    else:\n",
        "        state_dict = checkpoint['model']\n",
        "\n",
        "    # with checkpoint of vqa model\n",
        "    # reshape positional embedding to accomodate for image resolution change\n",
        "    # pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder.pos_embed'],model.visual_encoder)\n",
        "    # state_dict['visual_encoder.pos_embed'] = pos_embed_reshaped\n",
        "\n",
        "    # Check if the key exists before accessing it\n",
        "    if 'visual_encoder.pos_embed' in state_dict:\n",
        "        # reshape positional embedding to accomodate for image resolution change\n",
        "        pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder.pos_embed'],model.visual_encoder)\n",
        "        state_dict['visual_encoder.pos_embed'] = pos_embed_reshaped\n",
        "    else:\n",
        "        print(\"Warning: 'visual_encoder.pos_embed' not found in checkpoint. Skipping positional embedding interpolation.\")\n",
        "\n",
        "\n",
        "    if not args.evaluate:\n",
        "        if config['distill']:\n",
        "            m_pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder_m.pos_embed'],model.visual_encoder_m)\n",
        "            state_dict['visual_encoder_m.pos_embed'] = m_pos_embed_reshaped\n",
        "\n",
        "        for key in list(state_dict.keys()):\n",
        "            if 'bert' in key:\n",
        "                encoder_key = key.replace('bert.','')\n",
        "                state_dict[encoder_key] = state_dict[key]\n",
        "            # intialize text decoder as multimodal encoder (last 6 layers of model.text_encoder)\n",
        "            if 'text_encoder' in key:\n",
        "                if 'layer' in key:\n",
        "                    # print(key)\n",
        "                    encoder_keys = key.split('.')\n",
        "                    print(encoder_keys)\n",
        "                    # print(encoder_keys[4])\n",
        "                    tmp_fix_idx = 4 # for the downsized model, idx 5 is the layer number\n",
        "                    layer_num = int(encoder_keys[tmp_fix_idx]) # 4\n",
        "                    if layer_num<6:\n",
        "                        del state_dict[key]\n",
        "                        continue\n",
        "                    else:\n",
        "                        decoder_layer_num = (layer_num-6)\n",
        "                        encoder_keys[4] = str(decoder_layer_num)\n",
        "                        encoder_key = '.'.join(encoder_keys)\n",
        "                else:\n",
        "                    encoder_key = key\n",
        "                decoder_key = encoder_key.replace('text_encoder','text_decoder')\n",
        "                state_dict[decoder_key] = state_dict[key]\n",
        "\n",
        "                del state_dict[key]\n",
        "\n",
        "    msg = model.load_state_dict(state_dict,strict=False)\n",
        "    print('load checkpoint from %s'%args.checkpoint)\n",
        "    print(msg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VJmSxRhtFajJ"
      },
      "outputs": [],
      "source": [
        "# handle distributed training\n",
        "model_without_ddp = model\n",
        "if args.distributed:\n",
        "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
        "    model_without_ddp = model.module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VyQyvZE1FajJ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a3abd35-b700-4fec-fe03-463db6d58001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start eval\n",
            "Generate VQA test result:  [   0/5598]  eta: 6:32:50    time: 4.2106  data: 2.0382  max mem: 31908\n",
            "Generate VQA test result:  [  50/5598]  eta: 2:27:41    time: 1.5460  data: 0.0002  max mem: 32059\n",
            "Generate VQA test result:  [ 100/5598]  eta: 2:24:02    time: 1.5366  data: 0.0002  max mem: 32059\n",
            "Generate VQA test result:  [ 150/5598]  eta: 2:21:52    time: 1.5465  data: 0.0002  max mem: 32059\n",
            "Generate VQA test result:  [ 200/5598]  eta: 2:20:06    time: 1.5424  data: 0.0002  max mem: 32059\n",
            "Generate VQA test result:  [ 250/5598]  eta: 2:18:33    time: 1.5471  data: 0.0002  max mem: 32059\n",
            "Generate VQA test result:  [ 300/5598]  eta: 2:17:03    time: 1.5374  data: 0.0002  max mem: 32059\n",
            "Generate VQA test result:  [ 350/5598]  eta: 2:15:45    time: 1.5515  data: 0.0002  max mem: 32059\n",
            "Generate VQA test result:  [ 400/5598]  eta: 2:14:23    time: 1.5480  data: 0.0002  max mem: 32059\n",
            "Generate VQA test result:  [ 450/5598]  eta: 2:13:00    time: 1.5433  data: 0.0003  max mem: 32059\n",
            "Generate VQA test result:  [ 500/5598]  eta: 2:11:42    time: 1.5513  data: 0.0002  max mem: 32059\n",
            "Generate VQA test result:  [ 550/5598]  eta: 2:10:25    time: 1.5567  data: 0.0003  max mem: 32090\n",
            "Generate VQA test result:  [ 600/5598]  eta: 2:09:04    time: 1.5435  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [ 650/5598]  eta: 2:07:45    time: 1.5396  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [ 700/5598]  eta: 2:06:27    time: 1.5466  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [ 750/5598]  eta: 2:05:08    time: 1.5465  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [ 800/5598]  eta: 2:03:51    time: 1.5463  data: 0.0003  max mem: 32090\n",
            "Generate VQA test result:  [ 850/5598]  eta: 2:02:34    time: 1.5422  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [ 900/5598]  eta: 2:01:17    time: 1.5543  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [ 950/5598]  eta: 2:00:00    time: 1.5490  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1000/5598]  eta: 1:58:41    time: 1.5421  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1050/5598]  eta: 1:57:23    time: 1.5421  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1100/5598]  eta: 1:56:05    time: 1.5480  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1150/5598]  eta: 1:54:47    time: 1.5475  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1200/5598]  eta: 1:53:28    time: 1.5426  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1250/5598]  eta: 1:52:10    time: 1.5448  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1300/5598]  eta: 1:50:51    time: 1.5416  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1350/5598]  eta: 1:49:33    time: 1.5425  data: 0.0003  max mem: 32090\n",
            "Generate VQA test result:  [1400/5598]  eta: 1:48:16    time: 1.5490  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1450/5598]  eta: 1:46:58    time: 1.5448  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1500/5598]  eta: 1:45:41    time: 1.5529  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1550/5598]  eta: 1:44:23    time: 1.5381  data: 0.0003  max mem: 32090\n",
            "Generate VQA test result:  [1600/5598]  eta: 1:43:06    time: 1.5471  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1650/5598]  eta: 1:41:49    time: 1.5551  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1700/5598]  eta: 1:40:32    time: 1.5539  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1750/5598]  eta: 1:39:14    time: 1.5368  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1800/5598]  eta: 1:37:56    time: 1.5450  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1850/5598]  eta: 1:36:39    time: 1.5439  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1900/5598]  eta: 1:35:21    time: 1.5472  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [1950/5598]  eta: 1:34:04    time: 1.5439  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [2000/5598]  eta: 1:32:46    time: 1.5455  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [2050/5598]  eta: 1:31:28    time: 1.5387  data: 0.0002  max mem: 32090\n",
            "Generate VQA test result:  [2100/5598]  eta: 1:30:11    time: 1.5485  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2150/5598]  eta: 1:28:53    time: 1.5373  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2200/5598]  eta: 1:27:36    time: 1.5516  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2250/5598]  eta: 1:26:21    time: 1.5419  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2300/5598]  eta: 1:25:04    time: 1.5465  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2350/5598]  eta: 1:23:46    time: 1.5498  data: 0.0003  max mem: 32150\n",
            "Generate VQA test result:  [2400/5598]  eta: 1:22:29    time: 1.5446  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2450/5598]  eta: 1:21:11    time: 1.5534  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2500/5598]  eta: 1:19:54    time: 1.5484  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2550/5598]  eta: 1:18:36    time: 1.5476  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2600/5598]  eta: 1:17:19    time: 1.5481  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2650/5598]  eta: 1:16:01    time: 1.5359  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2700/5598]  eta: 1:14:44    time: 1.5464  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2750/5598]  eta: 1:13:26    time: 1.5396  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2800/5598]  eta: 1:12:08    time: 1.5399  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2850/5598]  eta: 1:10:51    time: 1.5454  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2900/5598]  eta: 1:09:33    time: 1.5401  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [2950/5598]  eta: 1:08:16    time: 1.5412  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3000/5598]  eta: 1:06:58    time: 1.5441  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3050/5598]  eta: 1:05:41    time: 1.5384  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3100/5598]  eta: 1:04:23    time: 1.5423  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3150/5598]  eta: 1:03:06    time: 1.5537  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3200/5598]  eta: 1:01:49    time: 1.5548  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3250/5598]  eta: 1:00:31    time: 1.5467  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3300/5598]  eta: 0:59:14    time: 1.5567  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3350/5598]  eta: 0:57:56    time: 1.5541  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3400/5598]  eta: 0:56:39    time: 1.5360  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3450/5598]  eta: 0:55:22    time: 1.5518  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3500/5598]  eta: 0:54:04    time: 1.5514  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3550/5598]  eta: 0:52:47    time: 1.5422  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3600/5598]  eta: 0:51:30    time: 1.5323  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3650/5598]  eta: 0:50:12    time: 1.5442  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3700/5598]  eta: 0:48:55    time: 1.5524  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3750/5598]  eta: 0:47:37    time: 1.5474  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3800/5598]  eta: 0:46:20    time: 1.5457  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3850/5598]  eta: 0:45:03    time: 1.5468  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3900/5598]  eta: 0:43:45    time: 1.5436  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [3950/5598]  eta: 0:42:28    time: 1.5563  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4000/5598]  eta: 0:41:11    time: 1.5438  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4050/5598]  eta: 0:39:53    time: 1.5432  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4100/5598]  eta: 0:38:36    time: 1.5456  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4150/5598]  eta: 0:37:18    time: 1.5373  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4200/5598]  eta: 0:36:01    time: 1.5432  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4250/5598]  eta: 0:34:44    time: 1.5428  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4300/5598]  eta: 0:33:26    time: 1.5399  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4350/5598]  eta: 0:32:09    time: 1.5516  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4400/5598]  eta: 0:30:52    time: 1.5538  data: 0.0003  max mem: 32150\n",
            "Generate VQA test result:  [4450/5598]  eta: 0:29:35    time: 1.5438  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4500/5598]  eta: 0:28:17    time: 1.5397  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4550/5598]  eta: 0:27:00    time: 1.5421  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4600/5598]  eta: 0:25:43    time: 1.5466  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4650/5598]  eta: 0:24:25    time: 1.5446  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4700/5598]  eta: 0:23:08    time: 1.5477  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4750/5598]  eta: 0:21:51    time: 1.5455  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4800/5598]  eta: 0:20:33    time: 1.5448  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4850/5598]  eta: 0:19:16    time: 1.5417  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4900/5598]  eta: 0:17:59    time: 1.5456  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [4950/5598]  eta: 0:16:41    time: 1.5532  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5000/5598]  eta: 0:15:24    time: 1.5402  data: 0.0003  max mem: 32150\n",
            "Generate VQA test result:  [5050/5598]  eta: 0:14:07    time: 1.5457  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5100/5598]  eta: 0:12:49    time: 1.5372  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5150/5598]  eta: 0:11:32    time: 1.5511  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5200/5598]  eta: 0:10:15    time: 1.5449  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5250/5598]  eta: 0:08:58    time: 1.5435  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5300/5598]  eta: 0:07:40    time: 1.5489  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5350/5598]  eta: 0:06:23    time: 1.5507  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5400/5598]  eta: 0:05:06    time: 1.5513  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5450/5598]  eta: 0:03:48    time: 1.5448  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5500/5598]  eta: 0:02:31    time: 1.5490  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5550/5598]  eta: 0:01:14    time: 1.5531  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result:  [5597/5598]  eta: 0:00:01    time: 1.5183  data: 0.0002  max mem: 32150\n",
            "Generate VQA test result: Total time: 2:24:15 (1.5462 s / it)\n",
            "result file saved to output/vqa_nopretrain_noTune/result/vqa_result_epoch0.json\n",
            "Time time 2:24:18\n"
          ]
        }
      ],
      "source": [
        "# run evaluation without training single GPU\n",
        "print(\"Start eval\")\n",
        "start_time = time.time()\n",
        "\n",
        "# for epoch in range(start_epoch, max_epoch):\n",
        "#     if epoch>0:\n",
        "#         lr_scheduler.step(epoch+warmup_steps)\n",
        "\n",
        "#     if not args.evaluate:\n",
        "#         if args.distributed:\n",
        "#             train_loader.sampler.set_epoch(epoch)\n",
        "\n",
        "#         train_stats = train(model, train_loader, optimizer, tokenizer, epoch, warmup_steps, device, lr_scheduler, config)\n",
        "\n",
        "#     if args.evaluate:\n",
        "#         break\n",
        "\n",
        "#     if utils.is_main_process():\n",
        "#         log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
        "#                       'epoch': epoch,\n",
        "#                     }\n",
        "#         with open(os.path.join(args.output_dir, \"log.txt\"),\"a\") as f:\n",
        "#             f.write(json.dumps(log_stats) + \"\\n\")\n",
        "\n",
        "#         save_obj = {\n",
        "#             'model': model_without_ddp.state_dict(),\n",
        "#             'optimizer': optimizer.state_dict(),\n",
        "#             'lr_scheduler': lr_scheduler.state_dict(),\n",
        "#             'config': config,\n",
        "#             'epoch': epoch,\n",
        "#         }\n",
        "#         torch.save(save_obj, os.path.join(args.output_dir, 'checkpoint_%02d.pth'%epoch))\n",
        "#     if args.distributed:\n",
        "#         dist.barrier()\n",
        "#     else:\n",
        "#         pass  # Skip barrier for non-distributed training\n",
        "\n",
        "# evaluation\n",
        "epoch=0\n",
        "vqa_result = evaluation(model, test_loader, tokenizer, device, config)\n",
        "result_file = save_result(vqa_result, args.result_dir, 'vqa_result_epoch%d'%epoch)\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print('Time time {}'.format(total_time_str))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'google drive: {GOOGLE_DRIVE_PATH} from colab drive: {args.output_dir}')"
      ],
      "metadata": {
        "id": "T52hIhCtaoJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0a1637-15d0-4f3b-80b1-8a28cdc732a5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google drive: /content/drive/MyDrive/DL_Project/ALBEF from colab drive: output/vqa_nopretrain_noTune\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save result to google drive\n",
        "!cp -r {args.output_dir} {GOOGLE_DRIVE_PATH}"
      ],
      "metadata": {
        "id": "qmVYMgYzgka2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# terminate colab runtime\n",
        "from google.colab import runtime\n",
        "runtime.unassign()\n"
      ],
      "metadata": {
        "id": "9o33GkkgsBGD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}